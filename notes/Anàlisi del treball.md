# Metodologia completa i justificable a nivell acad√®mic

Perfecte. Et proposo una **metodologia completa i justificable a nivell acad√®mic** per resoldre l'assignaci√≥, cobrint:

1. Selecci√≥ del millor model supervisat
2. Estudi d'overfitting
3. Transformaci√≥ a **semi-supervised learning** i an√†lisi
4. Comparaci√≥ final i conclusions

Tot est√† adaptat al **MagicTelescope dataset** (totes les features num√®riques + classe bin√†ria).

---

## 1. An√†lisi inicial del dataset

**Dataset**
- ~19.000 mostres
- 11 variables num√®riques cont√≠nues
- Classe bin√†ria (gamma = 1, hadron = 0)
- Classes moderadament desbalancejades (‚âà64% positives)

**Preprocessat recomanat**
- Normalitzaci√≥ / estandarditzaci√≥ (especialment per ANN i models probabil√≠stics)
- Split inicial:
    - 70% train
    - 15% validation
    - 15% test
- M√®triques:
    - Accuracy
    - Precision / Recall
    - F1-score
    - ROC-AUC (molt recomanada)

---

## 2. Aprenentatge supervisat: models candidats

### 2.1 Decision Trees

**Justificaci√≥**
- Model interpretable
- Captura no-linealitats
- Baseline excel¬∑lent

**Hiperpar√†metres clau**
- `max_depth`
- `min_samples_leaf`
- `min_samples_split`

**Avantatges**
- F√†cil d'interpretar
- R√†pid

**Inconvenients**
- Alta tend√®ncia a overfitting

üìå **S'esperen bons resultats en train per√≤ pitjor generalitzaci√≥**

---

### 2.2 Random Forest ‚≠ê (model molt fort per aquest dataset)

**Justificaci√≥**
- Redueix overfitting mitjan√ßant bagging
- Molt robust amb dades num√®riques
- Excel¬∑lent rendiment sense tuning extrem

**Hiperpar√†metres**
- `n_estimators`
- `max_depth`
- `max_features`
- `min_samples_leaf`

**Avantatges**
- Alta precisi√≥
- Poc sensible a soroll
- Maneja b√© interaccions complexes

**Inconvenients**
- Menys interpretable
- Cost computacional

üìå **Normalment el millor model cl√†ssic per MagicTelescope**

---

### 2.3 Artificial Neural Network (ANN)

**Arquitectura suggerida**
- Input: 11 neurones
- 1‚Äì2 hidden layers (32‚Äì64 neurones)
- Activaci√≥: ReLU
- Output: 1 neurona (sigmoid)

**Hiperpar√†metres**
- Learning rate
- Nombre de capes
- Dropout
- Batch size
- Epochs

**Avantatges**
- Alta capacitat expressiva
- Pot superar RF amb tuning acurat

**Inconvenients**
- Overfitting f√†cil
- Requereix m√©s calibratge

üìå **Interessant per l'estudi d'overfitting**

---

### 2.4 Probabilistic Graphical Models

Opcions raonables:
- Naive Bayes (Gaussian)
- Bayesian Network

**Justificaci√≥**
- Interpretaci√≥ probabil√≠stica
- Baseline probabil√≠stic

**Limitaci√≥**
- Assumpci√≥ d'independ√®ncia (Naive Bayes)
- Normalment pitjor rendiment que RF/ANN

üìå **√ötil com a refer√®ncia te√≤rica, no com a millor model**

---

## 3. Selecci√≥ del millor model

### Metodologia recomanada

1. Cross-validation (5 o 10 folds)
2. GridSearch / RandomSearch
3. Comparar ROC-AUC i F1

**Resultat esperat (habitual)**

| Model | ROC-AUC | Comentari |
|-------|---------|-----------|
| Decision Tree | Mitj√† | Overfitting |
| Random Forest | ‚≠ê Alt | Millor comprom√≠s |
| ANN | Alt (si ben ajustada) | Risc d'overfitting |
| Probabil√≠stic | Baix‚ÄìMitj√† | Baseline |

üìå **Model seleccionat:** Random Forest  
(ANN com a alternativa avan√ßada)

---

## 4. Estudi d'Overfitting

### 4.1 Metodologia

Per cada model:
- Comparar:
    - Accuracy (train vs validation)
    - Loss (ANN)
- Learning curves (dataset size vs performance)

---

### 4.2 Resultats t√≠pics

**Decision Tree**
- Train ‚âà 99%
- Validation ‚âà 80%  
‚û°Ô∏è Overfitting clar

**Random Forest**
- Train ‚âà 95%
- Validation ‚âà 90%  
‚û°Ô∏è Bona generalitzaci√≥

**ANN**
- Sense regularitzaci√≥:
    - Train ‚Üë‚Üë
    - Validation ‚Üì
- Amb:
    - Dropout
    - Early stopping  
‚û°Ô∏è Resultats estables

---

## 5. Transformaci√≥ a Semi-Supervised Learning

### 5.1 Escenari

Nom√©s un percentatge de les dades est√† etiquetat:
- 10%
- 20%
- 50%

La resta ‚Üí **unlabeled**

---

### 5.2 Estrat√®gia recomanada: Self-Training

1. Entrenar model amb dades etiquetades
2. Predir labels de dades no etiquetades
3. Seleccionar prediccions amb alta confian√ßa
4. Reentrenar el model
5. Repetir

üìå Funciona molt b√© amb Random Forest i ANN

---

### 5.3 Resultats esperats

| % Etiquetat | Supervisat | Semi-supervised |
|-------------|-----------|-----------------|
| 10% | Baix | ‚≠ê Millora clara |
| 20% | Mitj√† | Millora |
| 50% | Alt | Similar |

‚û°Ô∏è **El semi-supervised √©s especialment √∫til amb pocs labels**

---

## 6. Conclusions finals

- **Millor model supervisat:** Random Forest

- **Overfitting:**
    - Elevat en Decision Trees
    - Controlable en ANN amb regularitzaci√≥

- **Semi-supervised learning:**
    - Millora el rendiment quan hi ha pocs labels
    - Self-training √©s simple i efectiu

- **Recomanaci√≥ final:**
    - RF com a model base
    - ANN com a extensi√≥ avan√ßada

---

Si vols, puc:
- Escriure **codi Python (sklearn / PyTorch)**
- Preparar una **mem√≤ria d'entrega**
- Fer una **comparativa gr√†fica**
- Ajudar-te a **justificar-ho te√≤ricament per l'examen**

Nom√©s digues com ho necessites üëå
