{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0866c0da-c1a1-468b-886c-fca5540c4ff4",
   "metadata": {},
   "source": [
    "# Gradient descent (optimization algorithm)\n",
    "\n",
    "First-order optimization algorithm used to minimize (or maximize) functions by iteratively moving in the direction of the steepest descent.\n",
    "\n",
    "- First-order because it uses first derivatives or gradients.\n",
    "- The direction is determined by the negative of the gradient.\n",
    "- Widely used in machine learning to optimize model parameters; specifically, it is fundamental to training many types of neural networks.\n",
    "\n",
    "From a starting point, **Gradient Descent** takes (small) steps toward the function's minimum (maximum). \n",
    "\n",
    "![gradient descent](images/gd.png)\n",
    "\n",
    "\n",
    "In this notebook, we will code it and explore its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ca803-136a-46f1-a713-912506c445de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5160a-3880-47b0-9214-e0810803fea7",
   "metadata": {},
   "source": [
    "We need to define the following core *concepts of the optimization problem*:\n",
    "- **Objective function** ($f$): the function we want to optimize\n",
    "- **Gradient** ($\\nabla\\!f$): vector of partial derivatives for each dimension of the objective function\n",
    "\n",
    "For example, let's define the function to optimize\n",
    "\n",
    "$$f(x,y) = x^2+y^2$$\n",
    "\n",
    "Optimize, in this setting, means to find the point $(x,y)$ that minimizes the value of $f$. We know that, in this illustrative function $f$, the point $(0,0)$ is the minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bcfb7-d636-46a1-9a43-9af1eaf7c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function f(x, y) = x^2 + y^2\n",
    "def f(x, y):\n",
    "    return x**2 + y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a52bd-7d34-4275-8c33-0fb1d8d14adf",
   "metadata": {},
   "source": [
    "To calculate the gradient involves taking the **partial derivatives** of the function with respect to each dimension:\n",
    "$$\\nabla\\!f(x,y)=\\Big(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y}\\Big)$$\n",
    "\n",
    "- For the above function, the partial derivative of the first dimension ($x$) is:\n",
    "$$\\frac{\\partial f}{\\partial x}=2*x$$\n",
    "- and, for the second dimension ($y$):\n",
    "$$\\frac{\\partial f}{\\partial y}=2*y$$\n",
    "\n",
    "A partial derivative for any dimension can be understood as the *rate of change* of the function in the direction of the dimension. Combining the partial derivatives for all the dimensions, the **gradient** forms a vector or direction in the function's space. It is important to note that it *points in the opposite direction of the minimum* (\"uphill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f357b17-f199-483e-bf8e-4d3a77a385a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gradient of f(x, y) = x^2 + y^2\n",
    "def gradient(x, y):\n",
    "    return np.array([2 * x, 2 * y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43c783-79c6-49f2-a654-644f9d4cd077",
   "metadata": {},
   "source": [
    "Once we have defined the function and calculated its gradient, **gradient descent** involves following a simple procedure: given an initial point, repeatedly applying an update rule until the minimum point is reached. The key elements of the procedure are:\n",
    "- The initial or **starting point**, random or user-defined.\n",
    "- The **update rule**, a step in the opposite direction to the gradient (negative gradient).\n",
    "- The **learning rate**, aka the scale for the update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66006c7c-7b5a-4cb0-8ed4-f26146eee280",
   "metadata": {},
   "source": [
    "The **update rule** is just:\n",
    "\n",
    "$$x_{new} = x_{old} - \\alpha \\cdot \\frac{\\partial f}{\\partial x}(x_{old},y_{old})$$\n",
    "$$y_{new} = y_{old} - \\alpha \\cdot \\frac{\\partial f}{\\partial y}â€‹(x_{old},y_{old})$$\n",
    "\n",
    "That is, given a previous point $(x_{old},y_{old})$, a new point is obtained by *subtracting* from it the *scaled* gradient *evaluated* at the same point, $\\nabla\\!f(x_{old},y_{old})$:\n",
    "- *evaluating* the gradient at $(x_{old},y_{old})$ gives not only the direction but also the magnitude of the step,\n",
    "- *subtracting* because we need to move in the opposite direction of the gradient,\n",
    "- *scaled* by $\\alpha$ to control the rate of convergence.\n",
    "\n",
    "This process is repeated iteratively (the new *old* is the previous *new* point) until the point reaches the minimum point of the function (the gradient is evaluated to $\\sim 0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1fdd1-590d-49e7-b8a2-5db7fb9152d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent function\n",
    "# We save the whole path (all the intermediate points) for visualization\n",
    "def gradient_descent(start_point, learning_rate, max_iterations):\n",
    "    old_point = np.array(start_point, dtype=float)\n",
    "    path = [old_point.copy()]  # to store the path of (x, y) values\n",
    "\n",
    "    i = 0\n",
    "    converged=False\n",
    "    while not converged and i < max_iterations:\n",
    "        grad_eval = gradient(old_point[0], old_point[1])\n",
    "        new_point = #### YOUR CODE HERE ####\n",
    "        path.append(new_point.copy())\n",
    "        old_point = new_point\n",
    "        converged = np.all(np.abs(grad_eval) < 10-9)\n",
    "        i+=1\n",
    "\n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1252f93-6990-43a1-a7ea-b7d3e5599e41",
   "metadata": {},
   "source": [
    "Now, we have everything we need. Let's run an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5002960-6a54-43f6-b149-28da41f15625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "start_point = [-7, 7] # (x, y)\n",
    "learning_rate = 0.1\n",
    "iterations = 100\n",
    "\n",
    "# Run gradient descent\n",
    "path = gradient_descent(start_point, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdf131-061d-4509-b247-41d6ec3e0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that plots the objective function and the path of gradient descent\n",
    "def plot_gd(func, grad, path, xlimits=[-10,10],ylimits=[-10,10], vp=None):\n",
    "    # Configuration of the surface to show\n",
    "    x = np.linspace(xlimits[0], xlimits[1], 100)\n",
    "    y = np.linspace(ylimits[0], ylimits[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.array([func(xi, yi) for xi, yi in zip(X.ravel(), Y.ravel())])\n",
    "    Z = Z.reshape(X.shape)  # Reshape to match X and Y grid shapes\n",
    "    #Z = func(X, Y)\n",
    "    z_path = np.array([func(xi, yi) for xi, yi in zip(path[:, 0], path[:, 1])])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.5)\n",
    "    ax.plot(path[:, 0], path[:, 1], z_path, color='red', marker='o', markersize=5, label=\"Path towards minimum\")\n",
    "    \n",
    "    gr_unit=grad(path[0, 0], path[0, 1])\n",
    "    gr_unit/=np.sqrt(np.sum(gr_unit**2))\n",
    "    ax.quiver(\n",
    "            path[0, 0], path[0, 1], func(path[0, 0], path[0, 1]), # <-- starting point of vector\n",
    "            gr_unit[0], gr_unit[1], \n",
    "            func(path[0, 0]+gr_unit[0], path[0, 1]+gr_unit[1])-func(path[0, 0], path[0, 1]), # <-- directions of vector\n",
    "            color = 'blue', alpha = .8, arrow_length_ratio = 0.1, label=\"Unit vector of gradient at origin\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"f(x, y)\")\n",
    "    if vp is not None:\n",
    "        ax.view_init(**vp) #change viewpoint\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f0740-8cda-412f-b32a-02a08abe83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gd(f, gradient, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1243b-10f9-4788-a5b1-0092939da7e1",
   "metadata": {},
   "source": [
    "## To understand the procedure, let's go step by step.\n",
    "\n",
    "The selected **starting point** was $(x, y) = (-7, 7)$ and the learning rate $\\alpha = 0.1$.\n",
    "\n",
    "As we enter the procedure, the \"old\" point is the starting point\n",
    "\n",
    "- Iteration 1:\n",
    "    + Old point: $(x, y) = (-7, 7)$\n",
    "    + Gradient evaluation: $\\nabla f(-7, 7) = (2 \\cdot -7, 2 \\cdot 7) = (-14, 14)$\n",
    "    + Update:\n",
    "  $$\n",
    "  x_{\\text{new}} = x_{\\text{old}} - \\alpha \\cdot \\frac{\\partial f}{\\partial x}(x_{old},y_{old}) = -7 - 0.1 \\cdot (-14) = -7 + 1.4 = -5.6\n",
    "  $$\n",
    "  $$\n",
    "  y_{\\text{new}} = y_{\\text{old}} - \\alpha \\cdot \\frac{\\partial f}{\\partial y}(x_{old},y_{old}) = 7 - 0.1 \\cdot (14) = 7 - 1.4 = 5.6\n",
    "  $$\n",
    "    + New point: $(x, y) = (-5.6, 5.6)$\n",
    " \n",
    "- Iteration 2:\n",
    "    + Old point: $(x, y) = (-5.6, 5.6)$\n",
    "    + Gradient evaluation: $\\nabla f(-5.6, 5.6) = (2 \\cdot -5.6, 2 \\cdot 5.6) = (-11.2, 11.2)$\n",
    "    + Update:\n",
    "  $$\n",
    "  x_{\\text{new}} = -5.6 - 0.1 \\cdot (-11.2) = -5.6 + 1.12 = -4.48\n",
    "  $$\n",
    "  $$\n",
    "  y_{\\text{new}} = 5.6 - 0.1 \\cdot (11.2) = 5.6 - 1.12 = 4.48\n",
    "  $$\n",
    "    + New point: $(x, y) = (-4.48, 4.48)$\n",
    "\n",
    "- Iteration 3:\n",
    "    + Old point: $(x, y) = (-4.48, 4.48)$\n",
    "    + Gradient evaluation: $\\nabla f(-4.48, 4.48) = (2 \\cdot -4.48, 2 \\cdot 4.48) = (-8.96, 8.96)$\n",
    "    + Update:\n",
    "  $$\n",
    "  x_{\\text{new}} = -4.48 - 0.1 \\cdot (-8.96) = -4.48 + 0.896 = -3.584\n",
    "  $$\n",
    "  $$\n",
    "  y_{\\text{new}} = 4.48 - 0.1 \\cdot (8.96) = 4.48 - 0.896 = 3.584\n",
    "  $$\n",
    "    + New point: $(x, y) = (-3.584, 3.584)$\n",
    "\n",
    "Each iteration produces a point closer to \\((0, 0)\\), where the objective function $f(x, y) = x^2 + y^2$ has its minimum. As empirically shown above, by continuing this procedure, gradient descent will eventually converge near $(0, 0)$, *if the learning rate is well-chosen*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ceca68-cb56-4d83-9e41-754279ec9ba8",
   "metadata": {},
   "source": [
    "## The impact of choosing an appropriate learning rate\n",
    "The learning rate scales the update given by the gradient's evaluation. It controls how large each update step is. If $\\alpha$ is large, the algorithm might overshoot the minimum. If it is too small, convergence will be too slow. \n",
    "\n",
    "Let's see the previous example with different learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2caf5-0ca1-406e-97d1-181e49149587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#start_point = [-7, 7] # (x, y)\n",
    "learning_rate = 0.95\n",
    "#iterations = 100\n",
    "\n",
    "# Run gradient descent\n",
    "path = gradient_descent(start_point, learning_rate, iterations)\n",
    "plot_gd(f, gradient, path, vp={\"elev\":15, \"azim\":60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d196a8-af36-4f3b-8bc5-9404ba3312d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#start_point = [-7, 7] # (x, y)\n",
    "learning_rate = 0.01\n",
    "#iterations = 100\n",
    "\n",
    "# Run gradient descent\n",
    "path = gradient_descent(start_point, learning_rate, iterations)\n",
    "plot_gd(f, gradient, path, vp={\"elev\":15, \"azim\":60})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bf83b-4f1c-466e-a627-cad050cc47e2",
   "metadata": {},
   "source": [
    "# Relationship with machine learning\n",
    "\n",
    "The relationship between this optimization technique and machine learning might still be a little bit obscure. What is a \"point\" in my machine learning problem? what is the objective function? Let's try to clarify it, but it requires a change in our mindset.\n",
    "\n",
    "- In ML, we usually work with models (functions) that have a set of parameters (the ones we need to learn!). These models, given an input, provide an output.\n",
    "\n",
    "  For example: a simple regression model with parameters $(a,b)$:\n",
    "  $$y=a\\cdot x +b$$\n",
    "  We first fix the parameters' values (we usually learn them). For example, $a=2.5$ and $b=1.5$.\n",
    "  \n",
    "  Then, given a value for $x$, the model computes and returns a value for $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b79094-7693-4908-bcea-0c70fdfde060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, params={\"a\":2.5,\"b\":1.5}):\n",
    "    return x*params[\"a\"]+params[\"b\"]\n",
    "\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = model(x)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(x, y, color='green', linestyle='--', label='Linear regression model with (a,b)=(2.5,1.5)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7056e4f-20db-4ddb-9733-9310ca267b97",
   "metadata": {},
   "source": [
    "## Loss function: objective function of gradient descent\n",
    "\n",
    "However, the story explained above is rarely the case in ML practice. \n",
    "\n",
    "1. We usually have a dataset of $N$ cases $(x,y)$ which are (noisy) samples of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55860681-354b-4f02-9e2b-656b8df8e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(31) # fix the seed for reproducibility\n",
    "N = 6\n",
    "# Let's simulate a dataset with x-values between 0 and 10\n",
    "x = np.random.random(N)*10\n",
    "# and the corresponding observed y-values are the true evaluation of the function, plus some noise\n",
    "y = model(x) + np.random.normal(0, 2, size=N)\n",
    "dataset = np.array((x,y)).T\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad749b8-d545-4230-b1fc-a7d5f63277d1",
   "metadata": {},
   "source": [
    "2. We decide the **type of model** that we want to learn: a linear regression model.\n",
    "  \n",
    "   *Note that* we usually do *not know the real model* and, therefore, its type.\n",
    "\n",
    "3. We **find the parameters**, for the type of model chosen, that better match up the observed samples (data).\n",
    "\n",
    "   This step, the actual **learning step**, involves several decisions:\n",
    "\n",
    "   1. How do we decide which set of parameters matches the data better?\n",
    "   2. How do find that *best* set of parameters?\n",
    "\n",
    "  \n",
    "To answer question 3.B, our procedure could be **gradient descent**.\n",
    "   \n",
    "\n",
    "To answer question 3.A, we usually define some sort of metric that measures the difference between the observed data and the expected answer of the model configured with a specific set of parameters. This is called the **loss function** and it will be our objective function: find the set of parameters that minimize the loss function.\n",
    "\n",
    "A common loss function in regression problems is the **mean squared error**. \n",
    "$$\n",
    "\\text{loss} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "where $y_i$ is the observed $y$-value for the i-th case of the dataset, and $\\hat{y}_i$ is the corresponding prediction of the model. \n",
    "\n",
    "*Note that* we can define the loss as a function of the model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658c9c2-d8d7-4004-b15d-27c6897b86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as anp  # you will understand this later on\n",
    "\n",
    "def loss_function(a,b,data):\n",
    "#    return anp.mean((data[:,1]-model(data[:,0], params={\"a\":a,\"b\":b}))**2)# we could call the model\n",
    "    return anp.mean((data[:,1]-(data[:,0]*a+b))**2)# for efficiency, we just implement the model function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca00bd6-d724-43dd-a15a-21d7c59504c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function(3,4,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45499577-3c4e-42ff-b292-6971547c4ef7",
   "metadata": {},
   "source": [
    "In fact, as the dataset is fixed in this optimization problem, we can define the objective function as only dependent on the model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6bd42-8dbb-49b3-b457-1a3a8f4cd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda a, b : loss_function(a, b, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91a866-f964-466d-b48d-f165bfb96c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215d039-8764-485d-9a37-3244ae698df6",
   "metadata": {},
   "source": [
    "Now, we can apply gradient descent from a given starting point to find the point $(a,b)$ that minimizes $f$.\n",
    "\n",
    "We just need to calculate the gradient:\n",
    "\n",
    "1. Substitute $\\hat{y}_i$ by $a \\cdot x_i + b $ (model definition) into the loss function:\n",
    "$$\n",
    "\\text{loss} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - (a \\cdot x_i + b))^2\n",
    "$$\n",
    "\n",
    "2. The partial derivative with respect to $a$ is:\n",
    "$$\n",
    "\\frac{\\partial \\, \\text{loss}}{\\partial a} = \\frac{1}{N} \\sum_{i=1}^{N} 2 \\cdot (y_i - (a \\cdot x_i + b)) \\cdot (-x_i)\n",
    "=\n",
    "%\\frac{\\partial \\, \\text{loss}}{\\partial a} = \n",
    "-\\frac{2}{N} \\sum_{i=1}^{N} x_i \\cdot (y_i - (a \\cdot x_i + b))\n",
    "$$\n",
    "\n",
    "3. The partial derivative with respect to $b$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\, \\text{loss}}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^{N} 2 \\cdot (y_i - (a \\cdot x_i + b)) \\cdot (-1)\n",
    "%\\frac{\\partial \\, \\text{loss}}{\\partial b} \n",
    "= -\\frac{2}{N} \\sum_{i=1}^{N} (y_i - (a \\cdot x_i + b))\n",
    "$$\n",
    "So, now, we can write the gradient as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd891957-f271-4660-8218-213ae2a1ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gradient of f(a,b) = sum_1..N (yi - xi*a - b)^2\n",
    "def gradient_loss(a, b, data):\n",
    "    p_a = -2/data.shape[0]*np.sum(data[:,0]*(data[:,1]-(a*data[:,0]+b)))\n",
    "    p_b = #### YOUR CODE HERE ####\n",
    "    return np.array([p_a, p_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923ee74-a852-40c0-b179-76eb3961dbcb",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39e2f6-78f8-4212-b347-7d183ae955a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = lambda a, b : gradient_loss(a, b, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d0203-d4ba-4bc2-8e36-10ab5116dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11a6f9-5247-4a65-8c36-b852a894a072",
   "metadata": {},
   "source": [
    "Lucky enough, you do not need to manually calculate the derivatives and implement them. This can also be automatically done with automatic differentiation libraries like `autograd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdbdfd8-9b84-45c9-ad35-69973771871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import grad    # The only autograd function you may ever need\n",
    "\n",
    "autogradient = grad(f,[0,1])       # Obtain its gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607ed26-b5a4-43f9-ba34-4dae55d71848",
   "metadata": {},
   "outputs": [],
   "source": [
    "autogradient(3.,4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99d9f4-a606-4fb6-b9c1-19c8a152b3c3",
   "metadata": {},
   "source": [
    "Now we can run **gradient descent** for this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc06518-ed40-47cb-b35d-f6c35324b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "start_point = [4, 3] # (a, b)\n",
    "learning_rate = 0.015 # carefully chosen, try 0.01, 0.015, 0.02, 0.03\n",
    "iterations = 200\n",
    "\n",
    "# Run gradient descent\n",
    "path = gradient_descent(start_point, learning_rate, iterations)\n",
    "plot_gd(f, gradient, path, xlimits=[1,4],ylimits=[0,5], vp={\"elev\":15, \"azim\":110})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4685b-95af-442b-90a0-f39eae8c584c",
   "metadata": {},
   "source": [
    "We can also plot the models with the different parameters throught the path of gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc288527-6df8-4bce-ab35-52ce7e3b9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 50)\n",
    "nlinies = 5\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.scatter(dataset[:,0],dataset[:,1])\n",
    "\n",
    "y = model(x)\n",
    "plt.plot(x, y, color='green', linestyle='--', label='Real model with (a,b)=(2.5,1.5)')\n",
    "\n",
    "for i in np.linspace(0, path.shape[0] - 1, nlinies + 2, dtype=int):\n",
    "    y = model(x,{\"a\":path[i,0],\"b\":path[i,1]})\n",
    "    plt.plot(x, y, color='blue', alpha=0.1, linestyle='-', \n",
    "             label='It. '+str(i)+' with (a,b)=('+f\"{path[i,0]:.{2}f}\"+\",\"+f\"{path[i,1]:.{2}f}\"+')')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69b4b3-5da7-4afd-923e-fa872af06571",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- How do we choose the learning rate? Should it always be constant?\n",
    "- What if the problem has more than one minimum? What do you know about saddle points?\n",
    "- Implement **Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7b15d-384b-4ac8-8b15-3e609e497c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
